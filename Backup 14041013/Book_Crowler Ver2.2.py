# -*- coding: utf-8 -*-
"""
Book_Crawler_v2.2
- ุฌุฏุงุดุฏู ููุทู: get_book_div_from_page ู extract_details_from_div
- ุฏุงูููุฏ ุชุตูุฑ ุจุง ูุงู ุดุงุจฺฉ (ุจุฏูู -) ุจู ูพูุดู "Books Images"
- ุฏุฑุฌ ุชุตูุฑ ุฏุฑ ุงฺฉุณู ุจู ุตูุฑุช LinkToFile ู Placement = MoveAndSize
- ุงุณุชูุงุฏู ุงุฒ html.parser (ุจุฏูู lxml)
"""
import os
import re
import time
import random
import requests
import pandas as pd
from bs4 import BeautifulSoup
from urllib.parse import urlparse
import sys

# ุชูุธูุงุช
EXCEL_FILE = "Parsa Library.xlsx"
IMAGE_DIR = "Books Images"
BASE = "https://www.iranketab.ir"
HEADERS = {"User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64)"}
DELAY_RANGE = (0.8, 2.0)
UPDATE_ALL = False
EXCEL_VISIBLE = True

os.makedirs(IMAGE_DIR, exist_ok=True)

def log(msg):
    print(f"[{time.strftime('%H:%M:%S')}] {msg}")

def remove_old_images(ws, row, col):
    """
    ุชูุงู ุชุตุงูุฑ ุง Shapeูุง ฺฉู ุฏุฑ ุณููู ูุดุฎุต ุดุฏู (row, col) ูุฑุงุฑ ุฏุงุฑูุฏ ุฑุง ุญุฐู ูโฺฉูุฏ.
    ุจุฑุง ุฌููฺฏุฑ ุงุฒ ุจูู ุฑุฎุชู ุงูุฏฺฉุณโูุง ููฺฏุงู ุญุฐูุ ุงุฒ ุงูุชูุง ูุณุช ุดุฑูุน ูโฺฉูุฏ.
    """
    try:
        # ุชุนุฏุงุฏ ฺฉู Shapeูุง
        count = ws.Shapes.Count
        # ุญููู ูุนฺฉูุณ (ุงุฒ ุขุฎุฑ ุจู ุงูู)
        for i in range(count, 0, -1):
            shp = ws.Shapes.Item(i)
            # ุจุฑุฑุณ ุงูฺฉู ุขุง "ุณูููู ููฺฏุฑ" ุชุตูุฑุ ููุงู ุณููู ููุฑุฏ ูุธุฑ ูุงุณุชุ
            if shp.TopLeftCell.Row == row and shp.TopLeftCell.Column == col:
                shp.Delete()
    except Exception as e:
        print(f"Error removing old images: {e}")
        
def safe_get(url, allow_redirects=True, timeout=25):
    """
    ุฏุฑุฎูุงุณุช HTTP ุงูู ุจุง fallback ุฎูุฏฺฉุงุฑ ุจุฑุง ุฎุทุง SSL.
    ุงุจุชุฏุง ุจุง verify=True ุชูุงุด ูโฺฉูุฏ ู ุฏุฑ ุตูุฑุช SSLError ูุฌุฏุฏ ุจุง verify=False ุงูุชุญุงู ูโุดูุฏ.
    """
    try:
        time.sleep(random.uniform(*DELAY_RANGE))
        # ุชูุงุด ุงูู ุจุง ุชุฃุฏ SSL
        r = requests.get(url, headers=HEADERS, allow_redirects=allow_redirects, timeout=timeout, verify=True)
        r.raise_for_status()
        r.encoding = "utf-8"
        return r
    except requests.exceptions.SSLError as e:
        log(f"โ๏ธ ูุดุฏุงุฑ SSL ุฏุฑ GET {url}: {e} โ ุชูุงุด ูุฌุฏุฏ ุจุฏูู ุชุฃุฏ SSL ...")
        try:
            r = requests.get(url, headers=HEADERS, allow_redirects=allow_redirects, timeout=timeout, verify=False)
            r.raise_for_status()
            r.encoding = "utf-8"
            return r
        except Exception as e2:
            log(f"โ ุฎุทุง ุฏุฑ ุชูุงุด ุฏูู GET ุจุฏูู SSL ({url}): {e2}")
            return None
    except requests.exceptions.RequestException as e:
        log(f"โ๏ธ ุฎุทุง ุฏุฑ GET {url}: {e}")
        return None


# ---------- ุชุงุจุน ฺฉู URL ููุง ุตูุญู ฺฉุชุงุจ ุฑุง ุจุฑูโฺฏุฑุฏุงูุฏ ู HTML ุขู ุฑุง ----------
def get_final_book_url_and_html(isbn):
    isbn_clean = str(isbn).replace("-", "").strip()
    if not isbn_clean:
        return None, None
    search_url = f"{BASE}/result/{isbn_clean}?t=ฺฉุชุงุจ&s=0"
    r = safe_get(search_url)
    if not r:
        return None, None
    final_url = r.url
    html = r.text

    # ุงฺฏุฑ ุฑุฏุงุฑฺฉุช ูุณุชูู ุจู /book/ ุดุฏูุ ุฎูุจ ุงุณุช
    if "/book/" in final_url:
        return final_url, html

    # ูฺฏุฑูู ุงุฒ ุตูุญู ูุชุงุฌ ุงููู ููฺฉ /book/ ุฑุง ุจุฑุฏุงุฑ
    soup = BeautifulSoup(html, "html.parser")
    link_tag = soup.find("a", href=re.compile(r"^/book/"))
    if link_tag:
        href = link_tag.get("href")
        book_page_url = (BASE + href) if href.startswith("/") else href
        r2 = safe_get(book_page_url)
        if r2:
            return book_page_url, r2.text
    return None, None

# ---------- ุชุงุจุน ฺฉู ุงุฒ HTML ุตูุญู ุฏููุงู ููุงู div ูุณุฎู ููุฑุฏ ูุธุฑ ุฑุง ูพุฏุง ูโฺฉูุฏ ----------
def get_book_div_from_page(page_url, html, isbn):
    """
    ูุฑูุฏ: page_url (ููฺฉู ุงุณุช ุดุงูู fragment ูุซู #p-114766)ุ html ุตูุญูุ ู ุดุงุจฺฉ ููุฑุฏ ูุธุฑ
    ุฎุฑูุฌ: bs4 Tag ูุฑุจูุท ุจู ููุงู ูุณุฎู (div) ุง None ุงฺฏุฑ ุตูุญู ุชฺฉโฺฉุชุงุจ ุง ูพุฏุง ูุดุฏ.
    ุฑูุชุงุฑ:
      - ุงฺฏุฑ fragment (#p-XXXX) ูุฌูุฏ ุฏุงุดุช ุณุน ูโฺฉูุฏ div ุจุง ููุงู id ุฑุง ุจุฑฺฏุฑุฏุงูุฏ.
      - ุฏุฑ ุบุฑ ุงู ุตูุฑุชุ ูุณุช divูุง id^="p-" ุฑุง ูโฺฏุฑุฏุงูุฏ ู ุฏุฑ ูุฑ ฺฉุฏุงู ุฏูุจุงู span ุจุง 'ุดุงุจฺฉ:' ูโฺฏุฑุฏุฏ ู ููุงุณู ูโฺฉูุฏ.
      - ุงฺฏุฑ ูฺ ูพุฏุง ูุดุฏุ None ุจุงุฒูโฺฏุฑุฏุงูุฏ (ุญุงูุช ุชฺฉโฺฉุชุงุจ ุง ูุงูุดุฎุต).
    """
    if not html:
        return None
    soup = BeautifulSoup(html, "html.parser")

    # ุจุฑุฑุณ fragment ุฏุฑ URL (ูุซูุงู #p-30809)
    frag = urlparse(page_url).fragment if page_url else ""
    if frag:
        # ุชูุงุด ุจุฑุง ูพุฏุง ฺฉุฑุฏู div ุจุง ููุงู id
        candidate = soup.find(id=frag)
        if candidate:
            log(f" -> ุงูุชู div ุจุง fragment: #{frag}")
            return candidate

    # ูุณุช ฺฉุงูุฏุฏูุง: div ูุง ฺฉู id ุดุงู ุจุง p- ุดุฑูุน ูโุดูุฏ ุง ฺฉูุงุณ wrapper-product-acts ุฏุงุฎูุดุงู data-id ุฏุงุฑุฏ
    candidates = soup.select('div[id^="p-"], div.flex.gap-2.mb-3, div.wrapper-product-acts')
    # ุชุญูู ููุชุฑ ุดุฏู ุจุฑุง ูพุฏุง ฺฉุฑุฏู ฺฉุงุฑุชโูุง ูุงูุน: ุงุบูุจ structure ุฏุงุฑุง id="p-XXXX" ุงุณุช ู ุฏุฑ ฺฉูุงุฑ ุขู ุจุฎุด ูุชุง ููุฌูุฏ ุงุณุช
    # ุงูุง safest approach: ูพุฏุง ฺฉุฑุฏู ุชูุงู divูุง ฺฉู id ุดุฑูุน ุจุง p- ุฏุงุฑูุฏ
    candidates = soup.select('div[id^="p-"]')
    if not candidates:
        # ุตูุญู ููฺฉู ุงุณุช ุชฺฉโฺฉุชุงุจ ุจุงุดุฏ
        log(" -> ุตูุญู ุญุงู div[id^='p-'] ูุณุช โ ุงุญุชูุงูุงู ุตูุญู ุชฺฉโฺฉุชุงุจ.")
        return None

    clean_isbn = str(isbn).replace("-", "").strip()
    log(f" -> {len(candidates)} div ุจุง id^='p-' ูพุฏุง ุดุฏุ ุฏุฑ ุฌุณุชุฌู ุชุทุงุจู ุดุงุจฺฉ {clean_isbn} ...")
    for div in candidates:
        # ุฏุฑ ุฏุงุฎู ูุฑ div ูุนูููุงู ฺฉ span ุจุง ูุชู "ุดุงุจฺฉ:" ูุฌูุฏ ุฏุงุฑุฏ ู sibling ุขู ููุฏุงุฑ ุดุงุจฺฉ ุงุณุช
        isbn_span = div.find(lambda t: t.name in ["span","div"] and isinstance(t.string, str) and "ุดุงุจฺฉ" in t.string)
        if isbn_span:
            # ุณุน ฺฉูู ููุฏุงุฑ ุจุนุฏ ุง sibling ุฑุง ุจุฎูุงูู
            # ุญุงูุชโูุง ูุฎุชูู: <span>ุดุงุจฺฉ:</span><span>978-...</span>
            val = None
            nxt = isbn_span.find_next_sibling()
            if nxt and isinstance(nxt.get_text(strip=True), str) and nxt.get_text(strip=True):
                val = nxt.get_text(strip=True)
            else:
                # ุง ุณุงุฎุชุงุฑ ุฏฺฏุฑ: isbn_span.parent.find(...) 
                possible = isbn_span.parent.find_all("span")
                for s in possible:
                    txt = s.get_text(strip=True)
                    if re.search(r"\d{9,13}", txt):
                        val = txt
                        break
            if val:
                if str(val).replace("-", "").strip() == clean_isbn:
                    log(f" -> ุชุทุงุจู ุดุงุจฺฉ ุฏุฑ div id='{div.get('id')}' ุงูุช ุดุฏ ({val}).")
                    return div
    log(" -> ูฺ div ููุทุจู ุจุง ุดุงุจฺฉ ูพุฏุง ูุดุฏุ ุจุงุฒฺฏุดุช None (ุงุญุชูุงูุงู ุตูุญู ุชฺฉโฺฉุชุงุจ ุง ุณุงุฎุชุงุฑ ูุชูุงูุช).")
    return None

    # --- ุชุงุจุน ฺฉูฺฉ ููุดููุฏ ุจุฑุง ุงุณุชุฎุฑุงุฌ ุดูุงุฑู ุฌูุฏ ---
    def infer_collection_number(main_title: str, sub_title: str):
        # ุชุฑฺฉุจ ุจุฑุง ุฌุณุชุฌู ุฌุงูุนุ ุงูุง ุงูููุช ุฌุณุชุฌู ูุนูููุงู ุฑู sub_title ุงุณุช
        # ูุฑูุงูโุณุงุฒ ุงุนุฏุงุฏ ูุงุฑุณ ุจู ุงูฺฏูุณ
        def normalize_digits(txt):
            if not txt: return ""
            replacements = {'ฐ': '0', 'ฑ': '1', 'ฒ': '2', 'ณ': '3', 'ด': '4', 'ต': '5', 'ถ': '6', 'ท': '7', 'ธ': '8', 'น': '9'}
            for k, v in replacements.items():
                txt = txt.replace(k, v)
            return txt

        clean_sub = normalize_digits(sub_title)
        clean_main = normalize_digits(main_title)
        
        # 1. ุงูููุช ุงูู: ุจุงุฒู ุนุฏุฏ ุฏุงุฎู ูพุฑุงูุชุฒ ูุซู (11-10) ุง (10-11)
        # ูุซุงู: ฺฉุชุงุจ ุงูุง (11-10)
        range_match = re.search(r"\((\d+)\s*-\s*(\d+)\)", clean_sub)
        if range_match:
            n1, n2 = range_match.group(1), range_match.group(2)
            # ูุฑุชุจโุณุงุฒ ุงุนุฏุงุฏ (ฺฉู ููุดู 10 ู 11 ุจุงุดุฏ ูู 11 ู 10)
            nums = sorted([int(n1), int(n2)])
            return f"{nums[0]} ู {nums[1]}"

        # 2. ุงูููุช ุฏูู: ุนุฏุฏ ุฏุงุฎู ูพุฑุงูุชุฒ (ุจุง ุง ุจุฏูู ูุชู)
        # ูุซุงู: (12) ุง (ูฺฏูุจุงูุงู ฺฏุงููู 3) ุง (5)
        # ูพุชุฑู: ูพุฑุงูุชุฒ ุจุงุฒ -> (ุงุฎุชุงุฑ: ูุฑ ูุชู) -> ุนุฏุฏ -> ูพุฑุงูุชุฒ ุจุณุชู
        paren_match = re.search(r"\((?:[^)]*?\s+)?(\d{1,3})\)", clean_sub)
        if paren_match:
            return paren_match.group(1)

        # 3. ุงูููุช ุณูู: ุฌุฏุงฺฉููุฏู ุฎุงุต ูุซู "_" ุง "-" ูุจู ุงุฒ ุนุฏุฏ
        # ูุซุงู: ููุช ูุดุงูู _ 4
        sep_match = re.search(r"[_\-]\s*(\d{1,3})\b", clean_sub)
        if sep_match:
            return sep_match.group(1)

        # 4. ุงูููุช ฺูุงุฑู: ุนุฏุฏ ุฏุฑ ุงูุชูุง ูุชู (ุจุง ูุงุตูู ุงุฒ ฺฉููู ูุจู)
        # ูุซุงู: ูุตู ูุง ููฺฉุณ 5
        # ุดุฑุท: ุนุฏุฏ ุจุงุฏ 1 ุชุง 3 ุฑูู ุจุงุดุฏ (ุชุง ุณุงู ุงูุชุดุงุฑ ูุซู 1399 ุงุดุชุจุงู ูุดูุฏ)
        trailing_match = re.search(r"\s+(\d{1,3})$", clean_sub.strip())
        if trailing_match:
            return trailing_match.group(1)

        # 5. ุงูููุช ูพูุฌู: ุชุทุจู ุจุง ุนููุงู ุงุตู (ุฑูุด ูุฏู)
        # ูุซุงู: ุงฺฏุฑ ุนููุงู ุงุตู "ุชู ุฌุฏูู ูุง" ุจุงุดุฏ ู ุนููุงู ูุฑุน "ุชู ุฌุฏูู ูุง 2"
        if clean_main:
            stripped_main = re.escape(clean_main.strip())
            main_pattern = rf"{stripped_main}\s*(\d+)"
            m_main = re.search(main_pattern, clean_sub)
            if m_main:
                return m_main.group(1)

        return ""


# ---------- ุชุงุจุน ุงุณุชุฎุฑุงุฌ ุฌุฒุฆุงุช ููุท ุงุฒ ููุงู div (ุง ุฏุฑ ุตูุฑุช None ุงุฒ ุตูุญู ฺฉู) ----------
def extract_details_from_div(div, soup, isbn):
    info = {}

    # --- ุชุงุจุน ฺฉูฺฉ: ููุท ุดูุงุฑู ุฑุง ูพุฏุง ูโฺฉูุฏ (ูุชู ุฑุง ุชุบุฑ ููโุฏูุฏ) ---
    def detect_collection_number(text):
        if not text: return ""
        
        # ูุฑูุงูโุณุงุฒ ูููุช ุจุฑุง ุฌุณุชุฌู
        temp_text = text.strip()
        replacements = {'ฐ': '0', 'ฑ': '1', 'ฒ': '2', 'ณ': '3', 'ด': '4', 'ต': '5', 'ถ': '6', 'ท': '7', 'ธ': '8', 'น': '9'}
        for k, v in replacements.items():
            temp_text = temp_text.replace(k, v)

        # 1. ุงูููุช ุงูู: ุงูฺฏู "ุนุฏุฏ ู ุนุฏุฏ" (ูุซู: 6 ู 7)
        m_and = re.search(r"(\d+)\s*ู\s*(\d+)", temp_text)
        if m_and:
            nums = sorted([int(m_and.group(1)), int(m_and.group(2))])
            return f"{nums[0]} ู {nums[1]}"

        # 2. ุงูฺฏู ุจุงุฒู: (11-10)
        m_range = re.search(r"\((\d+)\s*-\s*(\d+)\)", temp_text)
        if m_range:
            nums = sorted([int(m_range.group(1)), int(m_range.group(2))])
            return f"{nums[0]} ู {nums[1]}"

        # 3. ุงูฺฏู ูพุฑุงูุชุฒ ุชฺฉ: (12)
        m_paren = re.search(r"\((?:[^)]*?\s+)?(\d{1,3})\)", temp_text)
        if m_paren: return m_paren.group(1)

        # 4. ุงูฺฏู ุฌุฏุงฺฉููุฏู ุงูุชูุง ุฎุท: _ 4 ุง - 4
        m_sep = re.search(r"[_\-]\s*(\d{1,3})$", temp_text)
        if m_sep: return m_sep.group(1)
        
        # 5. ุงูฺฏู ุฏู ููุทู: " : 1"
        m_colon = re.search(r":\s*(\d{1,3})", temp_text)
        if m_colon: return m_colon.group(1)

        # 6. ุนุฏุฏ ุฎุงู ุฏุฑ ุงูุชูุง ูุชู (ุฑุณฺฉ ุฏุงุฑุฏ ูู ุจุฑุง ูุฌููุนูโูุง ูุนููู ุงุณุช)
        m_trail = re.search(r"\s+(\d{1,3})$", temp_text)
        if m_trail: return m_trail.group(1)

        return ""

    # --- ุชุงุจุน ฺฉูฺฉ ุฎูุงูุฏู ุฌูุช ฺฉูุฏ/ููุฏุงุฑ ---
    def read_kv_pairs(block):
        kv = {}
        for row in block.select("div.flex.gap-1, div.flex.gap-2, div.flex.gap-3, div.flex.gap-4, div.flex.gap-0"):
            spans = row.find_all("span")
            if len(spans) >= 2:
                key = spans[0].get_text(strip=True).replace(":", "")
                val = spans[1].get_text(strip=True)
                kv[key] = val
        return kv

    if div is not None:
        try:
            # 1. ุงุณุชุฎุฑุงุฌ ุนูุงูู ุฎุงู
            h2_tag = div.find(lambda t: t.name in ["h2","h3"] and t.get_text(strip=True))
            if not h2_tag: h2_tag = div.find(itemprop="name")
            raw_h2 = h2_tag.get_text(strip=True) if h2_tag else ""

            sub_tag = h2_tag.find_next_sibling('div') if h2_tag else None
            raw_sub = ""
            if sub_tag and 'ltr' not in sub_tag.get('class', []):
                raw_sub = sub_tag.get_text(strip=True)

            # 2. ุซุจุช ุฏุฑ ุฏฺฉุดูุฑ (ุทุจู ุฏุณุชูุฑ: ููุท ุญุฐู ฺฉููู "ฺฉุชุงุจ" ุงุฒ ุนููุงู ุงุตู)
            # ุนููุงู ุงุตู
            final_main_title = re.sub(r"^ฺฉุชุงุจ\s+", "", raw_h2).strip()
            info["ุนููุงู ุงุตู"] = final_main_title
            
            # ุนููุงู ูุฑุน (ุจุฏูู ุชุบุฑ)
            info["ุนููุงู ูุฑุน"] = raw_sub

            # 3. ุงุณุชุฎุฑุงุฌ ุดูุงุฑู (ุฌุณุชุฌู ุฏุฑ ุฒุฑููุณุ ุงฺฏุฑ ูุจูุฏ ุฏุฑ ุนููุงู ุงุตู)
            found_num = detect_collection_number(raw_sub)
            if not found_num:
                found_num = detect_collection_number(raw_h2)
            
            info["ุดูุงุฑู ุฏุฑ ูุฌููุนู"] = found_num

        except Exception as e:
            print(f"Error extracting title: {e}")
            info["ุนููุงู ุงุตู"] = ""
            info["ุนููุงู ูุฑุน"] = ""
            info["ุดูุงุฑู ุฏุฑ ูุฌููุนู"] = ""

        # 4. ุชุตูุฑ
        a_img = div.find("a", href=re.compile(r"/Images/ProductImages/|/Files/AttachFiles/"))
        img_url = ""
        if a_img and a_img.get("href"):
            img_url = a_img.get("href")
        else:
            img_tag = div.find("img", itemprop="image")
            if img_tag and img_tag.get("src"):
                img_url = img_tag.get("src")

        if img_url:
            full_url = img_url if img_url.startswith("http") else (BASE + img_url)
            info["image_url"] = full_url
            info["iranketabImageName"] = os.path.basename(urlparse(full_url).path)
        else:
            info["image_url"] = ""
            info["iranketabImageName"] = ""

        # 5. ููุช
        final_price = ""
        old_price_tag = div.find("s", class_=lambda c: c and "price" in c)
        if old_price_tag:
            final_price = re.sub(r'\D', '', old_price_tag.get_text(strip=True))
        if not final_price:
            current_price_tag = div.find(class_="toman")
            if current_price_tag:
                final_price = re.sub(r'\D', '', current_price_tag.get_text(strip=True))
            else:
                alt = div.select_one(".price, .product-price")
                if alt: final_price = re.sub(r'\D', '', alt.get_text(strip=True))
        info["ููุช"] = final_price

        # 6. ุชุงุฑุฎโูุง ู ุณุงุฑ ููุฏูุง
        def get_val(cont, lbl):
            t = cont.find(lambda x: x.name=="span" and lbl in x.get_text(strip=True))
            return t.find_next_sibling("span").get_text(strip=True) if t and t.find_next_sibling("span") else ""

        info["ุณุงู ุงูุชุดุงุฑ ุดูุณ"] = get_val(div, "ุณุงู ุงูุชุดุงุฑ ุดูุณ")
        info["ุณุงู ุงูุชุดุงุฑ ููุงุฏ"] = get_val(div, "ุณุงู ุงูุชุดุงุฑ ููุงุฏ")

        def find_lbl(d, l):
            s = d.find(lambda t: t.name in ["span","div"] and isinstance(t.string, str) and l in t.get_text())
            if s:
                a = s.find_next("a")
                if a: return a.get_text(strip=True)
                sib = s.find_next_sibling()
                if sib: return sib.get_text(strip=True)
            return ""

        info["ููุณูุฏู"] = find_lbl(div, "ููุณูุฏู:")
        info["ูุชุฑุฌู"] = find_lbl(div, "ูุชุฑุฌู:")
        info["ูุงุดุฑ"] = find_lbl(div, "ุงูุชุดุงุฑุงุช:")

        orig = soup.find("div", class_=lambda c: c and "ltr" in c)
        info["ุนููุงู ุงูฺฏูุณ"] = orig.get_text(strip=True) if orig else ""

        kv = {}
        for block in div.select("div.card, div.absolute, div.flex"): kv.update(read_kv_pairs(block))
        if not kv: kv.update(read_kv_pairs(div))
        for k, v in kv.items(): info[k] = v

        if "ุดุงุจฺฉ" not in info:
            isbn_span = div.find(lambda t: t.name in ["span","div"] and isinstance(t.string, str) and "ุดุงุจฺฉ" in t.get_text())
            if isbn_span:
                nxt = isbn_span.find_next_sibling()
                if nxt: info["ุดุงุจฺฉ"] = nxt.get_text(strip=True)

        return info
    return {}



# ---------- pywin32 helper ----------
def ensure_pywin32():
    try:
        import win32com.client as win32
        return win32
    except Exception:
        raise SystemExit("โ ูุงุฒ ุจู pywin32 (python -m pip install pywin32)")

# ---------- ุฏุงูููุฏ ุชุตูุฑ (ุจุง ุงุตูุงุญ SSL) ----------
def download_image(img_url, isbn):
    if not img_url:
        return None
    isbn_clean = str(isbn).replace("-", "").strip()
    filename = f"{isbn_clean}.jpg"
    path = os.path.join(IMAGE_DIR, filename)
    if os.path.exists(path):
        return path
    
    try:
        # ุชูุงุด ุงูู: ุฏุงูููุฏ ุงุณุชุงูุฏุงุฑุฏ
        r = requests.get(img_url, headers=HEADERS, stream=True, timeout=30, verify=True)
    except requests.exceptions.SSLError:
        # ุชูุงุด ุฏูู: ุงฺฏุฑ ุฎุทุง SSL ุฏุงุฏุ ุจุฏูู ุจุฑุฑุณ ุงููุช ุฏุงูููุฏ ฺฉู
        try:
            r = requests.get(img_url, headers=HEADERS, stream=True, timeout=30, verify=False)
        except Exception:
            return None
    except Exception:
        return None

    try:
        r.raise_for_status()
        with open(path, "wb") as f:
            for chunk in r.iter_content(8192):
                f.write(chunk)
        return path
    except Exception:
        return None

# ---------------------------------------------------------
# ุชุงุจุน ุงุตู (MAIN)
# ---------------------------------------------------------
def main():
    win32 = ensure_pywin32()
    try:
        # ููุท ุจุฑุง ุฎูุงูุฏู ุชุนุฏุงุฏ ุฑฺฉูุฑุฏูุง ู ุงูุฏฺฉุณโูุง ุงุฒ ูพุงูุฏุงุณ ุงุณุชูุงุฏู ูโฺฉูู
        df_source = pd.read_excel(EXCEL_FILE, sheet_name=0, dtype=str).fillna("")
    except Exception as e:
        raise SystemExit(f"โ ุฎุทุง ุฏุฑ ุฎูุงูุฏู ูุงู ุงฺฉุณู: {e}")

    excel = win32.gencache.EnsureDispatch("Excel.Application")
    excel.Visible = True  # ูุดุงูุฏู ุฑููุฏ ฺฉุงุฑ
    wb = excel.Workbooks.Open(os.path.abspath(EXCEL_FILE))
    ws = wb.Worksheets(1)

    # 1. ููุดูโุจุฑุฏุงุฑ ุงุฒ ูุฏุฑูุง (Header Map)
    used_cols = ws.UsedRange.Columns.Count
    header_map = {}
    # ุฑุฏู 1 ุฑุง ูโุฎูุงูู
    for c in range(1, used_cols + 20): # ฺฉู ุจุดุชุฑ ูโุฎูุงูู ุชุง ูุทูุฆู ุดูู
        val = ws.Cells(1, c).Value
        if val:
            header_map[str(val).strip()] = c
        else:
            # ุงฺฏุฑ ุจู ุณููู ุฎุงู ุฑุณุฏู ู ุจุนุฏุด ูู ุฎุงู ุจูุฏุ ูุฑุถ ูโฺฉูู ุชูุงู ุดุฏู
            # (ุงูุง ฺูู ูโุฎูุงูู ุณุชูู ุงุถุงูู ฺฉููุ ุฏููโุชุฑู ุฑุงู UsedRange ุจูุฏ ฺฉู ุจุงูุง ุฒุฏู)
            pass

    # 2. ูุณุช ุณุชููโูุง ุงุฌุจุงุฑ ฺฉู ุจุงุฏ ุจุงุดูุฏ (ุงฺฏุฑ ูุจุงุดูุฏ ูโุณุงุฒู)
    required_cols = [
        "ุชุตูุฑ", 
        "ููุช", 
        "iranketabImageName", 
        "ุนููุงู ุงุตู", 
        "ุนููุงู ูุฑุน", 
        "ุดูุงุฑู ุฏุฑ ูุฌููุนู",
        "ุณุงู ุงูุชุดุงุฑ ุดูุณ",
        "ุณุงู ุงูุชุดุงุฑ ููุงุฏ"
    ]

    # ูพุฏุง ฺฉุฑุฏู ุขุฎุฑู ุณุชูู ูพุฑ ุดุฏู
    last_col_idx = 0
    if header_map:
        last_col_idx = max(header_map.values())
    
    for req in required_cols:
        if req not in header_map:
            last_col_idx += 1
            ws.Cells(1, last_col_idx).Value = req
            header_map[req] = last_col_idx
            log(f" + ุณุชูู ุฌุฏุฏ ุงุฌุงุฏ ุดุฏ: {req}")

    if "ุดุงุจฺฉ" not in header_map:
        wb.Close(SaveChanges=False)
        excel.Quit()
        raise SystemExit("โ ุณุชูู 'ุดุงุจฺฉ' ูพุฏุง ูุดุฏ.")

    total_rows = len(df_source)
    log(f"ุดุฑูุน ูพุฑุฏุงุฒุด {total_rows} ุฑฺฉูุฑุฏ...")

    # 3. ุญููู ุฑู ุฏุงุฏูโูุง
    for idx, row_data in df_source.iterrows():
        excel_row = int(idx) + 2  # ฺูู ูุฏุฑ ุฑุฏู 1 ุงุณุช ู ูพุงูุฏุงุณ ุงุฒ 0 ุดุฑูุน ูโฺฉูุฏ
        isbn = str(row_data.get("ุดุงุจฺฉ", "")).strip()

        if not isbn:
            continue

        # --- ุดุฑุท ูพุฑุด (Skip Logic) ---
        # ุงฺฏุฑ UPDATE_ALL ุฎุงููุด ุงุณุชุ ฺฺฉ ฺฉู ุขุง "ุนููุงู ุงุตู" ูพุฑ ุงุณุชุ
        if not UPDATE_ALL:
            # ููุฏุงุฑ ูุนู ุณููู ุนููุงู ุงุตู ุฑุง ุงุฒ ุงฺฉุณู ุฒูุฏู ุจุฎูุงู (ูู ุงุฒ ูพุงูุฏุงุณ ฺฉู ุดุงุฏ ูุฏู ุจุงุดุฏ)
            current_main_title = ws.Cells(excel_row, header_map["ุนููุงู ุงุตู"]).Value
            # ุงฺฏุฑ ุณููู ูพุฑ ุจูุฏ (None ูุจูุฏ ู ุฑุดุชู ุฎุงู ูุจูุฏ)
            if current_main_title and str(current_main_title).strip():
                # ูุงฺฏ ููโฺฉูู ุง ฺฉูุชุงู ูุงฺฏ ูโฺฉูู ุชุง ุดููุบ ูุดูุฏ
                # log(f"ุฑุฏู {excel_row} ุฑุฏ ุดุฏ (ุนููุงู ุฏุงุฑุฏ).")
                continue
        # -----------------------------

        log(f"\n[ุฑุฏู {excel_row}] ๐ ุดุงุจฺฉ: {isbn}")

        # ุฏุฑุงูุช ููฺฉ ู HTML
        book_url, html = get_final_book_url_and_html(isbn)
        if not book_url or not html:
            log(" -> โ ุตูุญู ฺฉุชุงุจ ูพุฏุง ูุดุฏ.")
            continue

        # ุงุณุชุฎุฑุงุฌ ุงุทูุงุนุงุช
        book_div = get_book_div_from_page(book_url, html, isbn)
        soup = BeautifulSoup(html, "html.parser")
        details = extract_details_from_div(book_div, soup, isbn)

        if not details:
            log(" -> โ ุงุทูุงุนุงุช ุงุณุชุฎุฑุงุฌ ูุดุฏ.")
            continue

        # 4. ุฏุฑุฌ ุงุทูุงุนุงุช ูุชู ุฏุฑ ุงฺฉุณู
        for key, val in details.items():
            if key == "ุชุตูุฑ": continue # ุชุตูุฑ ุฌุฏุงฺฏุงูู ููุฏู ูโุดูุฏ
            
            if key in header_map:
                col_idx = header_map[key]
                # ููุดุชู ููุฏุงุฑ ุฏุฑ ุณููู
                ws.Cells(excel_row, col_idx).Value = val

        # 5. ูุฏุฑุช ุชุตูุฑ (ุฏุงูููุฏุ ุญุฐู ูุจูุ ุฏุฑุฌ ุฌุฏุฏ)
        img_url = details.get("image_url", "")
        if img_url:
            local_img_path = download_image(img_url, isbn)
            if local_img_path:
                img_col = header_map["ุชุตูุฑ"]
                
                # ุงูู) ุญุฐู ุชุตุงูุฑ ูุฏู ุงู ุณููู
                remove_old_images(ws, excel_row, img_col)

                # ุจ) ุฏุฑุฌ ุชุตูุฑ ุฌุฏุฏ
                try:
                    cell_target = ws.Cells(excel_row, img_col)
                    left = cell_target.Left
                    top = cell_target.Top
                    width = cell_target.Width
                    height = cell_target.Height
                    
                    # AddPicture(Filename, LinkToFile, SaveWithDocument, Left, Top, Width, Height)
                    pic = ws.Shapes.AddPicture(
                        os.path.abspath(local_img_path), 
                        False, 
                        True, 
                        left, top, width, height
                    )
                    pic.Placement = 1 # Move and Size
                except Exception as e:
                    log(f"โ๏ธ ุฎุทุง ุฏุฑ ุฏุฑุฌ ุชุตูุฑ: {e}")
            else:
                log(" -> ุฏุงูููุฏ ุชุตูุฑ ูุงูููู ุจูุฏ.")

        # ุฐุฎุฑู ูููุช ูุฑ 10 ุฑฺฉูุฑุฏ (ุงุฎุชุงุฑุ ุจุฑุง ุงููุช ุจุดุชุฑ)
        if idx % 10 == 0:
            wb.Save()

        time.sleep(random.uniform(*DELAY_RANGE))

    # ูพุงุงู ฺฉุงุฑ
    wb.Save()
    log("โ ูพุงุงู ุนููุงุช. ูุงู ุฐุฎุฑู ุดุฏ.")
    # wb.Close(SaveChanges=True) # ุงฺฏุฑ ูโุฎูุงูุฏ ุจุงุฒ ุจูุงูุฏ ุงู ุฑุง ฺฉุงููุช ฺฉูุฏ
    # excel.Quit()

if __name__ == "__main__":
    main()